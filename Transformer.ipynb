{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"eFaW9rlEs1UI","executionInfo":{"status":"error","timestamp":1730755863144,"user_tz":300,"elapsed":45521,"user":{"displayName":"Mingwei Zhu","userId":"17413930663062778879"}},"outputId":"7b4f2dfd-7792-4128-b6cf-38706f9b6b88"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting datasets\n","  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n","  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n","Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n","  Attempting uninstall: fsspec\n","    Found existing installation: fsspec 2024.10.0\n","    Uninstalling fsspec-2024.10.0:\n","      Successfully uninstalled fsspec-2024.10.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.19.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.24.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.9.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.66.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.8.30)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting portalocker (from sacrebleu)\n","  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.9.11)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\n","Collecting colorama (from sacrebleu)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\n","Downloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n","Installing collected packages: portalocker, colorama, sacrebleu\n","Successfully installed colorama-0.4.6 portalocker-2.10.1 sacrebleu-2.4.3\n","Collecting colab-convert\n","  Downloading colab-convert-2.0.5.tar.gz (18 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting json5 (from colab-convert)\n","  Downloading json5-0.9.25-py3-none-any.whl.metadata (30 kB)\n","Downloading json5-0.9.25-py3-none-any.whl (30 kB)\n","Building wheels for collected packages: colab-convert\n","  Building wheel for colab-convert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for colab-convert: filename=colab_convert-2.0.5-py3-none-any.whl size=19207 sha256=66e60f287ff91ba4c3486bf94f91c3c5ef7f99880061e654943d0e9ae22f2601\n","  Stored in directory: /root/.cache/pip/wheels/a7/9f/0a/70f4be5eeba4a3fca9d7bcf68d5a4e97edb9f22be449cc1e8c\n","Successfully built colab-convert\n","Installing collected packages: json5, colab-convert\n","Successfully installed colab-convert-2.0.5 json5-0.9.25\n","Cloning into 'gtGPT'...\n","remote: Enumerating objects: 10, done.\u001b[K\n","remote: Counting objects: 100% (10/10), done.\u001b[K\n","remote: Compressing objects: 100% (8/8), done.\u001b[K\n","remote: Total 10 (delta 1), reused 10 (delta 1), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (10/10), 7.90 KiB | 7.90 MiB/s, done.\n","Resolving deltas: 100% (1/1), done.\n","Mounted at /content/drive\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/My Drive/CS7650/Final Project'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-ed1a97021f6d>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/My Drive/CS7650/Final Project\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/CS7650/Final Project'"]}],"source":["!pip install datasets\n","!pip install tokenizers\n","!pip install sacrebleu\n","!pip install colab-convert\n","!rm -rf gtGPT/\n","!rm -rf gtgpt\n","!git clone https://github.com/Helw150/gtGPT gtGPT\n","!mv gtGPT/gtgpt/ .\n","\n","from gtgpt.utils import set_seed\n","from google.colab import drive\n","import os\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import nltk\n","import re\n","import html\n","import random\n","import numpy as np\n","from collections import Counter\n","import torch\n","from torch.utils.data import Dataset, DataLoader, RandomSampler\n","from torch.nn.utils.rnn import pad_sequence\n","import torch.nn as nn\n","from sklearn.metrics import accuracy_score, f1_score\n","from tqdm import tqdm\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","import torch.nn.functional as F\n","from gtgpt.model import DummyMultiHeadedSelfAttention, DummyBlock, DummyTransformer, DummyEmbedding\n","from gtgpt.utils import set_seed\n","DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","torch.set_default_device(DEVICE)\n","os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:2\"\n","os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":16:8\"\n","\n","\n","drive.mount('/content/drive')\n","\n","os.chdir(\"/content/drive/My Drive/CS7650/Final Project\")"]},{"cell_type":"code","source":["train = pd.read_csv('train.tsv', sep='\\t', header=None)\n","test = pd.read_csv('test.tsv', sep='\\t', header=None)\n","valid = pd.read_csv('valid.tsv', sep='\\t', header=None)"],"metadata":{"id":"JIbzqH7pt3bi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Embedding(DummyEmbedding):\n","    def forward(self, idx):\n","        \"\"\"\n","        :param idx: intTensor of shape (B,T)\n","        :returns embeddings: floatTensor of shape (B,T,n_embd)\n","        \"\"\"\n","        B, T = idx.size()\n","        embeddings = None\n","\n","        token_embeddings = self.vocab_embeddings(idx)\n","\n","        positions = torch.arange(T, device=idx.device).expand(B, T)\n","\n","        position_embeddings = self.position_embeddings(positions)\n","\n","        embeddings = token_embeddings + position_embeddings\n","        return embeddings"],"metadata":{"id":"7udXSP34t3eA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class GenericSelfAttention(DummyMultiHeadedSelfAttention):\n","    def forward(self, x, attention_mask):\n","        \"\"\"\n","        :param x: float Tensor of shape (batch size, sequence length, embedding dimensionality)\n","        :param attention_mask: int Tensor of shape (batch size, 1, sequence length, sequence_length)\n","        :returns y: float Tensor of shape (batch size, sequence length, embedding dimensionality)\n","        \"\"\"\n","        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n","        y = None\n","        head_dim = C // self.n_head\n","        q = self.q(x).view(B, T, self.n_head, head_dim).transpose(1, 2)\n","        k = self.k(x).view(B, T, self.n_head, head_dim).transpose(1, 2)\n","        v = self.v(x).view(B, T, self.n_head, head_dim).transpose(1, 2)\n","\n","        scores = torch.matmul(q, k.transpose(-2, -1)) / (head_dim ** 0.5)\n","        if attention_mask is not None:\n","            scores = scores.masked_fill(attention_mask == 0, float('-inf'))\n","        attn = F.softmax(scores, dim=-1)\n","        attn = self.attn_dropout(attn)\n","\n","        y = torch.matmul(attn, v)\n","\n","        y = y.transpose(1, 2).contiguous().view(B, T, C)\n","        y = self.c_proj(y)\n","        y = self.hidden_dropout(y)\n","\n","        return y"],"metadata":{"id":"oG4EeoUzuskc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TransformerBlock(DummyBlock):\n","    def __init__(self, config):\n","        super().__init__(config, GenericSelfAttention)\n","\n","    # A Basic Transformer Block with Attention followed by an MLP\n","    # note the layer norms and residual information preserved at each step.\n","    def forward(self, x, attention_mask):\n","        x = x + self.attn(self.ln_1(x), attention_mask)\n","        x = x + self.mlpf(self.ln_2(x))\n","        return x"],"metadata":{"id":"blOp7YBnusnj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class GenericTransformer(DummyTransformer):\n","    def __init__(self, config):\n","        super().__init__(config, TransformerBlock, Embedding)\n","        self.block_size = config.block_size # Maximum Number of Tokens which can be encoded at once\n","        self.vocab_size = config.vocab_size\n","\n","    def get_attention_mask(self, num_tokens):\n","        \"\"\"\n","        Dummy For now, we will see how we use this later!\n","        \"\"\"\n","        B = num_tokens.shape[0]\n","        return torch.ones((B, self.block_size, self.block_size))[:, :num_tokens.max().item(), :num_tokens.max().item()]\n","\n","    def forward(self, idx, targets=None, hidden_cache=None, return_hidden=False):\n","        \"\"\"\n","        :param idx: int Tensor of shape (B,T)\n","        :param hidden_cache: float Tensor of shape (B,P_T,n_embd)\n","        :param targets: int Tensor of shape (B,T_T)\n","        :param return_hidden: bool\n","        (if return_hidden = None)\n","        :returns x: float Tensor of shape (B,T,n_embd)\n","        (else)\n","        :returns logits: float Tensor of shape (B, T, vocab_size)\n","        :returns loss: float Tensor of shape (B) or None\n","        \"\"\"\n","        num_tokens = (idx != -1).type(torch.int).sum(dim=1)\n","        if hidden_cache is not None:\n","          num_tokens = num_tokens + hidden_cache.shape[1]\n","        idx = idx.masked_fill(idx == -1, int(0)).type(torch.int)[:, :num_tokens.max().item()]\n","        if targets is not None:\n","          targets = targets[:, :num_tokens.max().item()]\n","        attention_mask = self.get_attention_mask(num_tokens)\n","\n","        x = self.transformer['embedding'](idx)\n","        if hidden_cache is not None:\n","            x = torch.cat([hidden_cache, x], dim=1)\n","\n","        for block in self.transformer['h']:\n","            x = block(x, attention_mask)\n","            x = self.transformer['ln_f'](x)\n","\n","        if x is not None:\n","            logits = self.lm_head(x)\n","\n","        if return_hidden:\n","            return x\n","\n","        # if we are given some desired targets also calculate the loss\n","        loss = None\n","        if targets is not None:\n","            s_logits = logits\n","            if hidden_cache is not None:\n","              s_logits = logits[:, hidden_cache.shape[1]-1:-1].contiguous()\n","              #print(logits[-1].argmax(dim=1))\n","            loss = F.cross_entropy(\n","                s_logits.reshape(-1, self.vocab_size), targets.reshape(-1), ignore_index=-1\n","            )\n","\n","\n","        return logits, loss"],"metadata":{"id":"dC9z1DtAuspx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Encoder(GenericTransformer):\n","    \"\"\"Encoder Style Transformer with Bidirectional Attention\"\"\"\n","    def get_attention_mask(self, num_tokens):\n","        \"\"\"\n","        :param num_tokens: int Tensor of shape (batch size)\n","        :returns attention_mask: int tensor of shape (batch_size, 1, max_tokens, max_tokens)\n","        \"\"\"\n","        B = num_tokens.shape[0]\n","        max_tokens = min(self.block_size, num_tokens.max().item())\n","\n","        T = torch.arange(max_tokens).expand(B, max_tokens)\n","\n","        attention_mask = (T < num_tokens.reshape(B, 1)).int()\n","\n","        attention_mask = attention_mask.reshape(B, 1, max_tokens).expand(B, max_tokens, max_tokens)\n","        return attention_mask.reshape(B, 1, max_tokens, max_tokens)"],"metadata":{"id":"yN_b9XYBussJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Decoder(Encoder):\n","    \"\"\"Decoder Style model with a Causal Attention Mask\"\"\"\n","\n","    def get_attention_mask(self, num_tokens):\n","        \"\"\"\n","        :param num_tokens: int Tensor of shape (batch size)\n","        :returns attention_mask: int tensor of shape (batch_size, 1, block_size, block_size)\n","        \"\"\"\n","        full_attention_mask = super().get_attention_mask(num_tokens)\n","        attention_mask = torch.tril(full_attention_mask)\n","        return attention_mask"],"metadata":{"id":"v5h7gJMrusud"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate(model, idx, max_new_tokens, temperature=1.0):\n","    \"\"\"\n","    :param idx: int Tensor of shape (B, T)\n","    :param max_new_tokens: int\n","    :param temperature: Float\n","    :returns idx: int Tensor of shape (B, T+max_new_tokens)\n","    \"\"\"\n","    for _ in range(max_new_tokens):\n","        logits, _ = model(idx)\n","\n","        logits = logits[:, -1, :] / temperature\n","\n","        prob = F.softmax(logits, dim=-1)\n","\n","        next = torch.multinomial(prob, num_samples=1)\n","\n","        idx = torch.cat([idx, next], dim=1)\n","    return idx"],"metadata":{"id":"UuYBBWOEuswe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class EncoderDecoder(nn.Module):\n","    \"\"\"Encoder-Decoder Model which combines the two architectures\"\"\"\n","    def __init__(self, encoder_config, decoder_config):\n","        super().__init__()\n","        # Add end of sequence token.\n","        decoder_config.vocab_size += 1\n","        self.vocab_size = decoder_config.vocab_size\n","        self.encoder = Encoder(encoder_config)\n","        self.decoder = Decoder(decoder_config)\n","\n","    def configure_optimizers(self, train_config):\n","        enc_groups = self.encoder.configure_optimizers(train_config)\n","        dec_groups = self.decoder.configure_optimizers(train_config)\n","        return enc_groups + dec_groups\n","\n","    def forward(self, prefix, targets=None):\n","        \"\"\"\n","        :param prefix: int Tensor of shape (B,P_T)\n","        :param idx: float Tensor of shape (B,P_T,n_embd)\n","        :returns logits: float Tensor of shape (B, vocab_size)\n","        :returns loss: float Tensor of shape (B) or None\n","        \"\"\"\n","        B = prefix.shape[0]\n","        idx = torch.tensor([[]]).repeat(B, 1)\n","        if targets is not None:\n","          idx = torch.cat((idx, targets), dim=1)\n","        encoder_hidden = self.encoder(prefix, return_hidden=True)\n","\n","        logits, loss = self.decoder(targets, hidden_cache=encoder_hidden)\n","        return logits, loss\n"],"metadata":{"id":"wsNdp1YxvE_j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prefix_generate(model, prefix, max_new_tokens, temperature=1.0):\n","    \"\"\"\n","    :param prefix: int Tensor of shape (B, T)\n","    :param max_new_tokens: int\n","    :param temperature: Float\n","    :returns idx: int Tensor of shape (B, max_new_tokens)\n","    \"\"\"\n","    idx = torch.tensor([[]], dtype=torch.long)\n","    with torch.no_grad():\n","        hidden_states = model.encoder(prefix, return_hidden=True)\n","        for _ in range(max_new_tokens):\n","            logits = model.decoder(idx, hidden_cache=hidden_states)\n","\n","            logits = logits[0][:, -1, :] / temperature\n","\n","            prob = F.softmax(logits, dim=-1)\n","\n","            next_token = torch.multinomial(prob, num_samples=1)\n","\n","            idx = torch.cat((idx, next), dim=1)\n","\n","        idx = idx[:, -max_new_tokens:]\n","    return idx"],"metadata":{"id":"0Nhvn4ZAvFBj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","from torch.utils.data.dataloader import DataLoader\n","from gtgpt.trainer import Trainer\n","\n","import pickle\n","\n","class SortDataset(Dataset):\n","    \"\"\"\n","    Dataset for the Sort problem. E.g. for problem length 6:\n","    Input: 0 0 2 1 0 1 -> Output: 0 0 0 1 1 2\n","    Which will feed into the transformer concatenated as:\n","    input:  0 0 2 1 0 1 0 0 0 1 1\n","    output: I I I I I 0 0 0 1 1 2\n","    where I is \"ignore\", as the transformer is reading the input sequence\n","    \"\"\"\n","\n","    def __init__(self, split, length=6, num_digits=3):\n","        assert split in {'train', 'test'}\n","        self.split = split\n","        self.length = length\n","        self.num_digits = num_digits\n","\n","    def __len__(self):\n","        return 10000 # ...\n","\n","    def get_vocab_size(self):\n","        return self.num_digits\n","\n","    def get_block_size(self):\n","        # the length of the sequence that will feed into transformer,\n","        # containing concatenated input and the output, but -1 because\n","        # the transformer starts making predictions at the last input element\n","        return 20\n","\n","    def __getitem__(self, idx):\n","\n","        # use rejection sampling to generate an input example from the desired split\n","        while True:\n","            # generate some random integers\n","            inp = torch.randint(self.num_digits, size=(self.length,), dtype=torch.long)\n","            # half of the time let's try to boost the number of examples that\n","            # have a large number of repeats, as this is what the model seems to struggle\n","            # with later in training, and they are kind of rate\n","            if torch.rand(1).item() < 0.5:\n","                if inp.unique().nelement() > self.length // 2:\n","                    # too many unqiue digits, re-sample\n","                    continue\n","            # figure out if this generated example is train or test based on its hash\n","            h = hash(pickle.dumps(inp.tolist()))\n","            inp_split = 'test' if h % 4 == 0 else 'train' # designate 25% of examples as test\n","            if inp_split == self.split:\n","                break # ok\n","\n","        # solve the task: i.e. sort\n","        sol = torch.sort(inp)[0]\n","\n","        # concatenate the problem specification and the solution\n","        cat = torch.cat((inp, sol), dim=0)\n","\n","        # the inputs to the transformer will be the offset sequence\n","        x = cat[:self.length].clone()\n","        y = cat[self.length:].clone()\n","        # we only want to predict at output locations, mask out the loss at the input locations\n","        return x, y"],"metadata":{"id":"AfvTkMX1vFDu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from gtgpt.trainer import Trainer\n","from tqdm import tqdm\n","from tokenizers import Tokenizer\n","from tokenizers.pre_tokenizers import ByteLevel\n","from tokenizers.trainers import UnigramTrainer, BpeTrainer\n","from tokenizers.models import Unigram, BPE\n","from datasets import load_dataset\n","import random\n","\n","class LMDataset(Dataset):\n","    def __init__(self, split, data, tokenizer, model):\n","        assert split in {'train', 'test'}\n","        self.model_type = \"EncDec\" if issubclass(type(model), EncoderDecoder) else \"Dec\"\n","        if split == \"train\":\n","          self.start_split = 0\n","          self.end_split = 30000\n","        else:\n","          self.start_split = 30000\n","          self.end_split = 40000\n","        self.split = split\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        self.block_size = max([len(self.tokenizer.encode(inp)) for inp in self.data])\n","        self.process()\n","\n","    def __len__(self):\n","        return len(self.data[self.start_split:self.end_split])\n","\n","    def get_vocab_size(self):\n","        return self.tokenizer.get_vocab_size()\n","\n","    def get_block_size(self):\n","        # the length of the sequence that will feed into transformer,\n","        # containing concatenated input and the output, but -1 because\n","        # the transformer starts making predictions at the last input element\n","        return self.block_size\n","\n","    def process(self):\n","      new_data = []\n","      for inp in tqdm(self.data):\n","        if self.model_type == \"EncDec\":\n","          x_inp = inp.split(\"[SEP]\")[0] + \"[SEP]\"\n","          y_inp = inp.split(\"[SEP]\")[1]\n","          x = self.tokenizer.encode(x_inp)\n","          y = self.tokenizer.encode(y_inp)\n","        else:\n","          x = self.tokenizer.encode(inp)\n","          y = x[1:]\n","          x = x[:-1]\n","        x = x + ([-1] * (self.get_block_size() - len(x)))\n","        y = y + ([-1] * (self.get_block_size() - len(y)))\n","        new_data.append((x, y))\n","      self.data = new_data\n","\n","    def __getitem__(self, idx):\n","      x, y = self.data[self.start_split + idx]\n","      return torch.tensor(x), torch.tensor(y)\n","\n","def format_review(row):\n","  return {\"text\": f\"{row['translation']['eng']}[SEP]{row['translation']['engyay']}[END]\"}"],"metadata":{"id":"z4aocZVpvFFg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Tokenizer():\n","  def __init__(self):\n","    self.DELIM = \"|[DELIM]|\"\n","    self.special_tokens = [\"[SEP]\", \"[END]\"]\n","    self.special_tokens = [self.stringify(list(bytes(tok, \"utf-8\"))) for tok in self.special_tokens]\n","    self.vocab_size = 256 + len(self.special_tokens)\n","\n","  def stringify(self, b_enc):\n","    s_enc = [str(b) for b in b_enc]\n","    return self.DELIM.join(s_enc)\n","\n","  def get_vocab_size(self):\n","    return self.vocab_size\n","\n","  def encode(self, inp):\n","    s_enc = self.stringify(list(bytes(inp, \"utf-8\")))\n","    for i, tok in enumerate(self.special_tokens):\n","      s_enc = s_enc.replace(tok, str(255+i+1))\n","    return [int(s) for s in s_enc.split(self.DELIM)]\n","\n","  def decode(self, inp):\n","    s_enc = self.stringify(inp)\n","    for i, tok in enumerate(self.special_tokens):\n","      s_enc = s_enc.replace(str(255+i+1), tok)\n","    return  bytes([int(c) for c in s_enc.split(self.DELIM)])"],"metadata":{"id":"_pMCOXxvvVHs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","torch.set_default_device(DEVICE)\n","def train(data, model_type=\"Decoder\",\n","          learning_rate = 5e-4,\n","          batch_size = 16,\n","          max_iters = 10000,\n","          dec_n_layer=1,\n","          dec_n_embd=52,\n","          dec_n_head = 1,\n","          enc_n_layer=None,\n","          enc_n_embd=None,\n","          enc_n_head=None):\n","  # Model Setup\n","  tokenizer = Tokenizer()\n","  dec_config = DummyTransformer.get_default_config()\n","  dec_config.vocab_size = tokenizer.get_vocab_size()\n","  dec_config.block_size = max([len(tokenizer.encode(inp)) for inp in data])\n","  dec_config.n_layer = dec_n_layer\n","  dec_config.n_embd = dec_n_embd\n","  dec_config.n_head = dec_n_head\n","  if model_type == \"Decoder\":\n","    model = Decoder(dec_config)\n","  else:\n","    enc_config = DummyTransformer.get_default_config()\n","    enc_config.vocab_size = tokenizer.get_vocab_size()\n","    enc_config.block_size = max([len(tokenizer.encode(inp)) for inp in data])\n","    enc_config.n_layer = enc_n_layer\n","    enc_config.n_embd = enc_n_embd\n","    enc_config.n_head = enc_n_head\n","    model = EncoderDecoder(enc_config, dec_config)\n","\n","  # Training Config\n","  train_config = Trainer.get_default_config()\n","  train_config.learning_rate = learning_rate\n","  train_config.max_iters = max_iters\n","  train_config.batch_size = batch_size\n","  train_config.num_workers = 0\n","  train_config.device = DEVICE\n","  train_ds = LMDataset(\"train\", data, tokenizer, model)\n","  # Training Loop\n","  trainer = Trainer(train_config, model, train_ds)\n","  def batch_end_callback(trainer):\n","      if trainer.iter_num % 100 == 0:\n","          tqdm.write(f\"iter_dt {trainer.iter_dt * 1000:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}\")\n","          prefix = torch.tensor([tokenizer.encode(\"translate this to piglatin[SEP]\")])\n","          if model_type == \"Decoder\":\n","            output = generate(model, prefix, 100, 0.1)\n","          else:\n","            output = prefix_generate(model, prefix, 100, 0.1)\n","          print(tokenizer.decode(output.cpu().numpy()[0]).split(bytes(\"[END]\", \"utf-8\"))[0])\n","  trainer.set_callback('on_batch_end', batch_end_callback)\n","  trainer.run()\n","  return model, trainer"],"metadata":{"id":"nFBytfEhvVKE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df = pd.read_csv('train.tsv', sep='\\t', header=None)\n","train_df = train_df.iloc[:, 1:3]\n","train_df.columns = ['label', 'data']\n","train_df['formatted_text'] = train_df.apply(lambda row: f\"{row['data']}[SEP]{row['label']}[END]\", axis=1)\n","\n","data = train_df['formatted_text'].tolist()"],"metadata":{"id":"29KJyyjHWEaQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model, trainer = train(data, model_type=\"Decoder\",\n","          learning_rate = 5e-4,\n","          batch_size = 16,\n","          max_iters = 10000,\n","          dec_n_layer=4,\n","          dec_n_embd=128,\n","          dec_n_head =4,\n","          enc_n_layer=None,\n","          enc_n_embd=None,\n","          enc_n_head=None)\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AtCyF4nJvVMa","executionInfo":{"status":"ok","timestamp":1730745790679,"user_tz":-480,"elapsed":650963,"user":{"displayName":"Junyuan Quan","userId":"04708075856958314177"}},"outputId":"650aa37e-e92b-430d-b4de-1a5b91af95c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["number of parameters: 1.24M\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10240/10240 [00:01<00:00, 5296.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["running on device cuda:0\n","iter_dt 0.00ms; iter 0: train loss 5.57106\n","b\"translate this to piglatin[SEP]md\\xb0'Le \\x1bo\\xc6\\x9fg\\x1c=\\xd6\\xc0O\\x08enh\\x94\\x86\\xc2\\x9a*\\xb2H\\x17\\xf4*EE\\xcf\\xb2\\xb1:\\xfc\\xea\\x05(T J\\xb9\\xbd\\xc5 e]\\xdeth\\x8a\\xfcrox$\\xa1o\\xe5\\x11p\\xcb\\xb7\\x84\\xae\\xf3\\xea\\xea\\xb3\\xda\\xae\\xc66\\xf1\\xda\\xef\\x84wr9\\x92\\x8fW\\x82\\x94\\x86\\xacse\\x0fk\\xb9C\\xc5[SEP]\\x08\\xe3\"\n","iter_dt 52.28ms; iter 100: train loss 2.57359\n","b'translate this to piglatin[SEP]ban the t the the the the the the the the the the the the the the the are the the the the t the the '\n","iter_dt 51.97ms; iter 200: train loss 2.39484\n","b'translate this to piglatin[SEP]me'\n","iter_dt 50.96ms; iter 300: train loss 2.39573\n","b'translate this to piglatin[SEP]haly-true'\n","iter_dt 70.26ms; iter 400: train loss 2.34575\n","b'translate this to piglatin[SEP]fare'\n","iter_dt 50.75ms; iter 500: train loss 2.26843\n","b'translate this to piglatin[SEP]faly-true'\n","iter_dt 50.80ms; iter 600: train loss 2.22815\n","b'translate this to piglatin[SEP]farue'\n","iter_dt 55.14ms; iter 700: train loss 2.13346\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.89ms; iter 800: train loss 2.05268\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.06ms; iter 900: train loss 1.99137\n","b'translate this to piglatin[SEP]halse'\n","iter_dt 51.07ms; iter 1000: train loss 1.97688\n","b'translate this to piglatin[SEP]false'\n","iter_dt 50.77ms; iter 1100: train loss 1.99209\n","b'translate this to piglatin[SEP]bare'\n","iter_dt 51.14ms; iter 1200: train loss 1.86959\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.31ms; iter 1300: train loss 1.86741\n","b'translate this to piglatin[SEP]mostly-true'\n","iter_dt 51.90ms; iter 1400: train loss 1.74457\n","b'translate this to piglatin[SEP]bare'\n","iter_dt 51.35ms; iter 1500: train loss 1.80795\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.15ms; iter 1600: train loss 1.76684\n","b'translate this to piglatin[SEP]false'\n","iter_dt 53.01ms; iter 1700: train loss 1.75347\n","b'translate this to piglatin[SEP]false'\n","iter_dt 50.74ms; iter 1800: train loss 1.75529\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.65ms; iter 1900: train loss 1.66330\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.51ms; iter 2000: train loss 2.39153\n","b'translate this to piglatin[SEP]barely-true'\n","iter_dt 51.49ms; iter 2100: train loss 1.63150\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.64ms; iter 2200: train loss 1.59201\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.10ms; iter 2300: train loss 1.59418\n","b'translate this to piglatin[SEP]false'\n","iter_dt 52.04ms; iter 2400: train loss 1.61629\n","b'translate this to piglatin[SEP]half-true'\n","iter_dt 53.78ms; iter 2500: train loss 1.57150\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.99ms; iter 2600: train loss 1.56973\n","b'translate this to piglatin[SEP]true'\n","iter_dt 50.81ms; iter 2700: train loss 1.61760\n","b'translate this to piglatin[SEP]false'\n","iter_dt 54.76ms; iter 2800: train loss 1.62847\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.24ms; iter 2900: train loss 1.56804\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.59ms; iter 3000: train loss 1.44465\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.13ms; iter 3100: train loss 1.48422\n","b'translate this to piglatin[SEP]false'\n","iter_dt 50.92ms; iter 3200: train loss 1.46884\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.89ms; iter 3300: train loss 1.40220\n","b'translate this to piglatin[SEP]barely-true'\n","iter_dt 51.19ms; iter 3400: train loss 1.46969\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.13ms; iter 3500: train loss 1.46013\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.97ms; iter 3600: train loss 1.47349\n","b'translate this to piglatin[SEP]false'\n","iter_dt 50.67ms; iter 3700: train loss 1.48888\n","b'translate this to piglatin[SEP]mostly-true'\n","iter_dt 52.80ms; iter 3800: train loss 1.43585\n","b'translate this to piglatin[SEP]false'\n","iter_dt 50.70ms; iter 3900: train loss 1.36302\n","b'translate this to piglatin[SEP]half-true'\n","iter_dt 51.32ms; iter 4000: train loss 1.36143\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.45ms; iter 4100: train loss 1.30823\n","b'translate this to piglatin[SEP]false'\n","iter_dt 53.82ms; iter 4200: train loss 1.37307\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.31ms; iter 4300: train loss 1.51453\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.18ms; iter 4400: train loss 1.35238\n","b'translate this to piglatin[SEP]false'\n","iter_dt 52.61ms; iter 4500: train loss 1.39276\n","b'translate this to piglatin[SEP]false'\n","iter_dt 50.86ms; iter 4600: train loss 1.29984\n","b'translate this to piglatin[SEP]false'\n","iter_dt 50.80ms; iter 4700: train loss 1.39691\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.06ms; iter 4800: train loss 1.35416\n","b'translate this to piglatin[SEP]false'\n","iter_dt 50.52ms; iter 4900: train loss 1.41293\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.73ms; iter 5000: train loss 1.39425\n","b'translate this to piglatin[SEP]barely-true'\n","iter_dt 51.27ms; iter 5100: train loss 1.32076\n","b'translate this to piglatin[SEP]barely-true'\n","iter_dt 51.72ms; iter 5200: train loss 1.59470\n","b'translate this to piglatin[SEP]half-true'\n","iter_dt 51.36ms; iter 5300: train loss 1.39096\n","b'translate this to piglatin[SEP]fire'\n","iter_dt 52.22ms; iter 5400: train loss 1.29867\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.67ms; iter 5500: train loss 1.33128\n","b'translate this to piglatin[SEP]false'\n","iter_dt 50.73ms; iter 5600: train loss 1.38491\n","b'translate this to piglatin[SEP]true'\n","iter_dt 51.87ms; iter 5700: train loss 1.25400\n","b'translate this to piglatin[SEP]true'\n","iter_dt 52.47ms; iter 5800: train loss 1.29113\n","b'translate this to piglatin[SEP]pants-fire'\n","iter_dt 52.32ms; iter 5900: train loss 1.34099\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.21ms; iter 6000: train loss 1.39663\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.55ms; iter 6100: train loss 1.33555\n","b'translate this to piglatin[SEP]false'\n","iter_dt 53.18ms; iter 6200: train loss 1.21341\n","b'translate this to piglatin[SEP]barely-true'\n","iter_dt 51.16ms; iter 6300: train loss 1.30558\n","b'translate this to piglatin[SEP]half-true'\n","iter_dt 51.66ms; iter 6400: train loss 1.28101\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.42ms; iter 6500: train loss 1.21351\n","b'translate this to piglatin[SEP]true'\n","iter_dt 50.61ms; iter 6600: train loss 1.27698\n","b'translate this to piglatin[SEP]true'\n","iter_dt 52.47ms; iter 6700: train loss 1.27508\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.24ms; iter 6800: train loss 1.27280\n","b'translate this to piglatin[SEP]false'\n","iter_dt 50.91ms; iter 6900: train loss 1.31463\n","b'translate this to piglatin[SEP]mostly-true'\n","iter_dt 51.61ms; iter 7000: train loss 1.26110\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.73ms; iter 7100: train loss 1.21418\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.52ms; iter 7200: train loss 1.23608\n","b'translate this to piglatin[SEP]false'\n","iter_dt 52.82ms; iter 7300: train loss 1.16973\n","b'translate this to piglatin[SEP]barely-true'\n","iter_dt 52.08ms; iter 7400: train loss 1.22532\n","b'translate this to piglatin[SEP]barely-true'\n","iter_dt 52.50ms; iter 7500: train loss 1.36754\n","b'translate this to piglatin[SEP]barely-true'\n","iter_dt 50.91ms; iter 7600: train loss 1.20928\n","b'translate this to piglatin[SEP]barely-true'\n","iter_dt 51.94ms; iter 7700: train loss 1.27086\n","b'translate this to piglatin[SEP]false'\n","iter_dt 53.08ms; iter 7800: train loss 1.21233\n","b'translate this to piglatin[SEP]barely-true'\n","iter_dt 50.76ms; iter 7900: train loss 1.25165\n","b'translate this to piglatin[SEP]barely-true'\n","iter_dt 51.76ms; iter 8000: train loss 1.24004\n","b'translate this to piglatin[SEP]false'\n","iter_dt 50.46ms; iter 8100: train loss 1.31488\n","b'translate this to piglatin[SEP]false'\n","iter_dt 56.57ms; iter 8200: train loss 1.27084\n","b'translate this to piglatin[SEP]false'\n","iter_dt 50.99ms; iter 8300: train loss 1.20623\n","b'translate this to piglatin[SEP]barely-true'\n","iter_dt 51.05ms; iter 8400: train loss 1.19976\n","b'translate this to piglatin[SEP]mostly-true'\n","iter_dt 51.21ms; iter 8500: train loss 1.26493\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.51ms; iter 8600: train loss 1.20581\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.86ms; iter 8700: train loss 1.21955\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.10ms; iter 8800: train loss 1.27872\n","b'translate this to piglatin[SEP]barely-true'\n","iter_dt 53.00ms; iter 8900: train loss 1.16507\n","b'translate this to piglatin[SEP]false'\n","iter_dt 52.62ms; iter 9000: train loss 1.20383\n","b'translate this to piglatin[SEP]barely-true'\n","iter_dt 55.43ms; iter 9100: train loss 1.23768\n","b'translate this to piglatin[SEP]false'\n","iter_dt 52.83ms; iter 9200: train loss 1.30399\n","b'translate this to piglatin[SEP]false'\n","iter_dt 50.80ms; iter 9300: train loss 1.25560\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.47ms; iter 9400: train loss 1.13341\n","b'translate this to piglatin[SEP]false'\n","iter_dt 54.29ms; iter 9500: train loss 1.20456\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.46ms; iter 9600: train loss 1.19096\n","b'translate this to piglatin[SEP]true'\n","iter_dt 52.35ms; iter 9700: train loss 1.13774\n","b'translate this to piglatin[SEP]true'\n","iter_dt 52.00ms; iter 9800: train loss 1.18643\n","b'translate this to piglatin[SEP]false'\n","iter_dt 51.71ms; iter 9900: train loss 1.21403\n","b'translate this to piglatin[SEP]barely-true'\n"]},{"output_type":"execute_result","data":{"text/plain":["Decoder(\n","  (transformer): ModuleDict(\n","    (embedding): Embedding(\n","      (vocab_embeddings): Embedding(258, 128)\n","      (position_embeddings): Embedding(3205, 128)\n","    )\n","    (h): ModuleList(\n","      (0-3): 4 x TransformerBlock(\n","        (ln_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","        (attn): GenericSelfAttention(\n","          (k): Linear(in_features=128, out_features=128, bias=True)\n","          (v): Linear(in_features=128, out_features=128, bias=True)\n","          (q): Linear(in_features=128, out_features=128, bias=True)\n","          (c_proj): Linear(in_features=128, out_features=128, bias=True)\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (hidden_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","        (mlp): ModuleDict(\n","          (c_fc): Linear(in_features=128, out_features=512, bias=True)\n","          (c_proj): Linear(in_features=512, out_features=128, bias=True)\n","          (act): NewGELU()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=128, out_features=258, bias=False)\n",")"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["torch.save(model.state_dict(), 'transformer_decoder.pth')"],"metadata":{"id":"cTM21lQOtfRh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Decoder(dec_config)\n","\n","model.load_state_dict(torch.load('trained_model.pth'))\n","\n","model.eval()"],"metadata":{"id":"u7FejHfAt5O2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sacrebleu.metrics import BLEU\n","\n","def eval(trainer, data, tokenizer):\n","    bleu = BLEU()\n","    results = []\n","    mistakes_printed_already = 0\n","    tgts = []\n","    cands = []\n","    for sent in tqdm(data[10000:10100]):\n","        inp = torch.tensor([tokenizer.encode(sent.split(\"[SEP]\")[0] + \"[SEP]\")])\n","        tgt = bytes(sent.split(\"[SEP]\")[1].split(\"[END]\")[0], \"utf-8\")\n","        cat = generate(model, inp, model.block_size-len(inp[0]), 0.1)\n","        tgt_candidate = tokenizer.decode(cat.cpu().numpy()[0])\n","        tgt_candidate = tgt_candidate.split(b\"[END]\")[0].split(b\"[SEP]\")[1]\n","        # compare the predicted sequence to the true sequence\n","        tgts.append([str(tgt)])\n","        cands.append(str(tgt_candidate))\n","        correct = (tgt == tgt_candidate)\n","        results.append(correct)\n","    results = torch.tensor(results).type(torch.float)\n","    print(\"\\n\\nExact Match: %d/%d = %.2f%% correct\" % (torch.sum(results), len(results), 100*torch.mean(results)))\n","    score = bleu.corpus_score(cands, tgts)\n","    print(score)\n","\n","    return results\n","\n","with torch.no_grad():\n","  results = eval(trainer, data, Tokenizer())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"njITskx7vVOV","executionInfo":{"status":"ok","timestamp":1730749385325,"user_tz":-480,"elapsed":2318938,"user":{"displayName":"Junyuan Quan","userId":"04708075856958314177"}},"outputId":"f0e44ac8-7957-440c-9e45-58560e37c7d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 100/100 [59:54<00:00, 35.95s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","\n","Exact Match: 21/100 = 21.00% correct\n","BLEU = 0.00 100.0/0.0/0.0/0.0 (BP = 1.000 ratio = 1.000 hyp_len = 1 ref_len = 1)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"C9z0UmdtvVQ1"},"execution_count":null,"outputs":[]}]}